{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Titanic Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script type=\"text/javascript\">\n",
       "        \n",
       "        var nb = null;\n",
       "        var kernel = null;\n",
       "\n",
       "        if (IPython && \n",
       "            IPython.notebook && \n",
       "            IPython.notebook.kernel &&\n",
       "            IPython.notebook.kernel.info_reply &&\n",
       "            IPython.notebook.kernel.info_reply.status &&\n",
       "            IPython.notebook.kernel.info_reply.status == \"ok\") {\n",
       "            nb = IPython.notebook; \n",
       "            kernel = IPython.notebook.kernel;\n",
       "        }\n",
       "        \n",
       "        if (nb && kernel) {\n",
       "            var filename = nb.notebook_path;\n",
       "            var basename = filename.substring(filename.lastIndexOf('/') + 1);\n",
       "            var msg = 'Detected filename: '+basename;\n",
       "            document.getElementById(\"detected_notebook_filename_tag\").innerHTML=msg;\n",
       "            var command = \"import os; os.environ['NB_FILENAME']= '\" + basename + \"'\";\n",
       "            kernel.execute(command);\n",
       "        } else {\n",
       "            var msg = 'Not connected to kernel.';\n",
       "            document.getElementById(\"detected_notebook_filename_tag\").innerHTML=msg;\n",
       "        }\n",
       "        </script><pre id=\"detected_notebook_filename_tag\"></pre>\n",
       "      "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%datalabframework getfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-30 14:06:46,314 - jovyan - __main__ - INFO - init - {'notebook': {'filename': 'lr.ipynb', 'filepath': '/home/jovyan/work/notebooks/models'}, 'datalab': {'framework': '0.1'}, 'project': {'rootpath': '/home/jovyan/work/notebooks', 'main': 'main.ipynb'}}\n"
     ]
    }
   ],
   "source": [
    "import datalabframework as dlf\n",
    "logger = dlf.log.initLogger(__name__, kafka_topic=\"datalab\", kafka_servers=\"kafka:9092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "\n",
    "def lr_model(df):\n",
    "   \n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "    model = lr.fit(df)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/jovyan/work/data'\n",
    "d = {   \n",
    "    'input_sample' : 1.0,\n",
    "    'input_source' : DATA_ROOT + '/titanic/data/set/train/features.parquet',\n",
    "    'output_model' : DATA_ROOT + '/titanic/models/lr.model'\n",
    "}\n",
    "p = dlf.params.config_fromdict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(dlf.project.filename()).getOrCreate()\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      "\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|PassengerId|Survived|Pclass|Sex   |Age               |SibSp|Parch|Fare   |Embarked|Title |\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|1          |0       |3     |male  |22.0              |1    |0    |7.25   |S       |Mr    |\n",
      "|2          |1       |1     |female|38.0              |1    |0    |71.2833|C       |Mrs   |\n",
      "|3          |1       |3     |female|26.0              |0    |0    |7.925  |S       |Miss  |\n",
      "|4          |1       |1     |female|35.0              |1    |0    |53.1   |S       |Mrs   |\n",
      "|5          |0       |3     |male  |35.0              |0    |0    |8.05   |S       |Mr    |\n",
      "|6          |0       |3     |male  |28.467886947074096|0    |0    |8.4583 |Q       |Mr    |\n",
      "|7          |0       |1     |male  |54.0              |0    |0    |51.8625|S       |Mr    |\n",
      "|8          |0       |3     |male  |2.0               |3    |1    |21.075 |S       |Master|\n",
      "|9          |1       |3     |female|27.0              |0    |2    |11.1333|S       |Mrs   |\n",
      "|10         |1       |2     |female|14.0              |1    |0    |30.0708|C       |Mrs   |\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(p.input_source)\n",
    "df.printSchema()\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InteractiveShell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NotebookFinder' object has no attribute 'find_spec'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-61eea28eadf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m df_features = features.feature_vector(df, \n\u001b[1;32m      3\u001b[0m                   \u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   ['Pclass', \n",
      "\u001b[0;32m/opt/conda/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec_legacy\u001b[0;34m(finder, name, path)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/datalabframework/project.py\u001b[0m in \u001b[0;36mfind_module\u001b[0;34m(self, fullname, path)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotebookLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/datalabframework/project.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m\"\"\"Module Loader for Jupyter Notebooks\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'InteractiveShell' is not defined"
     ]
    }
   ],
   "source": [
    "from features import features\n",
    "df_features = features.feature_vector(df, \n",
    "                  'PassengerId', \n",
    "                  'Survived', \n",
    "                  ['Pclass', \n",
    "                   'Sex', \n",
    "                   'Age', \n",
    "                   'SibSp', \n",
    "                   'Parch',\n",
    "                   'Fare', \n",
    "                   'Embarked', \n",
    "                   'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = lr_model(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# no overwrite mode in python for spark yet :(\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(p.output_model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.save(p.output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_features.show(n=5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(df_features)\n",
    "prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "metric = evaluator.evaluate(prediction)\n",
    "metric_name = evaluator.getMetricName()\n",
    "\n",
    "print(\"Evaluation {} : {}\".format(metric_name, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
