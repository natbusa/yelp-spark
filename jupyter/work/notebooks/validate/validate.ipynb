{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script type=\"text/javascript\">\n",
       "        \n",
       "        var nb = null;\n",
       "        var kernel = null;\n",
       "\n",
       "        if (IPython && \n",
       "            IPython.notebook && \n",
       "            IPython.notebook.kernel &&\n",
       "            IPython.notebook.kernel.info_reply &&\n",
       "            IPython.notebook.kernel.info_reply.status &&\n",
       "            IPython.notebook.kernel.info_reply.status == \"ok\") {\n",
       "            nb = IPython.notebook; \n",
       "            kernel = IPython.notebook.kernel;\n",
       "        }\n",
       "        \n",
       "        if (nb && kernel) {\n",
       "            var filename = nb.notebook_path;\n",
       "            var basename = filename.substring(filename.lastIndexOf('/') + 1);\n",
       "            var msg = 'Detected filename: '+basename;\n",
       "            document.getElementById(\"detected_notebook_filename_tag\").innerHTML=msg;\n",
       "            var command = \"import os; os.environ['NB_FILENAME']= '\" + basename + \"'\";\n",
       "            kernel.execute(command);\n",
       "        } else {\n",
       "            var msg = 'Not connected to kernel.';\n",
       "            document.getElementById(\"detected_notebook_filename_tag\").innerHTML=msg;\n",
       "        }\n",
       "        </script><pre id=\"detected_notebook_filename_tag\"></pre>\n",
       "      "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%datalabframework getfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-30 14:24:41,070 - jovyan - __main__ - INFO - init - {'notebook': {'filepath': '/home/jovyan/work/notebooks/validate', 'filename': 'validate.ipynb'}, 'project': {'rootpath': '/home/jovyan/work/notebooks', 'main': 'main.ipynb'}, 'datalab': {'framework': '0.1'}}\n"
     ]
    }
   ],
   "source": [
    "import datalabframework as dlf\n",
    "logger = dlf.log.initLogger(__name__, kafka_topic=\"datalab\", kafka_servers=\"kafka:9092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "\n",
    "def auc(df, model):\n",
    "    prediction = model.transform(df)\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "    metric = evaluator.evaluate(prediction)\n",
    "    metric_name = evaluator.getMetricName()\n",
    "\n",
    "    return metric_name, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/jovyan/work/data'\n",
    "d = {   \n",
    "    'input_sample' : 1.0,\n",
    "    'input_source' : DATA_ROOT + '/titanic/data/set/train/features.parquet',\n",
    "    'input_model' : DATA_ROOT + '/titanic/models/lr.model'\n",
    "}\n",
    "\n",
    "p = dlf.params.config_fromdict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(dlf.project.filename()).getOrCreate()\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      "\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|PassengerId|Survived|Pclass|Sex   |Age               |SibSp|Parch|Fare   |Embarked|Title |\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|1          |0       |3     |male  |22.0              |1    |0    |7.25   |S       |Mr    |\n",
      "|2          |1       |1     |female|38.0              |1    |0    |71.2833|C       |Mrs   |\n",
      "|3          |1       |3     |female|26.0              |0    |0    |7.925  |S       |Miss  |\n",
      "|4          |1       |1     |female|35.0              |1    |0    |53.1   |S       |Mrs   |\n",
      "|5          |0       |3     |male  |35.0              |0    |0    |8.05   |S       |Mr    |\n",
      "|6          |0       |3     |male  |28.467886947074096|0    |0    |8.4583 |Q       |Mr    |\n",
      "|7          |0       |1     |male  |54.0              |0    |0    |51.8625|S       |Mr    |\n",
      "|8          |0       |3     |male  |2.0               |3    |1    |21.075 |S       |Master|\n",
      "|9          |1       |3     |female|27.0              |0    |2    |11.1333|S       |Mrs   |\n",
      "|10         |1       |2     |female|14.0              |1    |0    |30.0708|C       |Mrs   |\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(p.input_source)\n",
    "df.printSchema()\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/jovyan/work/notebooks/features/features.ipynb\n"
     ]
    }
   ],
   "source": [
    "from features import features\n",
    "df_features = features.feature_vector(df, \n",
    "                  'PassengerId', \n",
    "                  'Survived', \n",
    "                  ['Pclass', \n",
    "                   'Sex', \n",
    "                   'Age', \n",
    "                   'SibSp', \n",
    "                   'Parch',\n",
    "                   'Fare', \n",
    "                   'Embarked', \n",
    "                   'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "model = LogisticRegressionModel.load(p.input_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metric_name, metric = auc(df_features, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation areaUnderROC : 0.8742077567933189\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation {} : {}\".format(metric_name, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
